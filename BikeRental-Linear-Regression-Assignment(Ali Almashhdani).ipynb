{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7acfb20e",
   "metadata": {},
   "source": [
    "# Step 1: Reading and Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819aa3f0",
   "metadata": {},
   "source": [
    "# Step 2: Reading and Checking the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Dataset\n",
    "df = pd.read_csv(\"day.csv\")\n",
    "# Checking the Data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c82afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Description of the Columns of Dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Shape of Dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69505ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the info about columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991236c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Null Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd2929b",
   "metadata": {},
   "source": [
    "# Step 3: Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2980c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the (season) column.\n",
    "df['season']=df.season.map({1: 'Spring', 2: 'Summer',3:'Fall', 4:'Winter' })\n",
    "# Mapping the (month) column.\n",
    "df['mnth']=df.mnth.map({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'June',7:'July',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\n",
    "# Mapping the (weathersit) column.\n",
    "df['weathersit']=df.weathersit.map({1: 'Clear',2:'Mist + Cloudy',3:'Light Snow',4:'Snow + Fog'})\n",
    "# Mapping the (weekday) column.\n",
    "df['weekday']=df.weekday.map({0:'Sun',1:'Mon',2:'Tue',3:'Wed',4:'Thu',5:'Fri',6:'Sat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted Columns like (instant),(dteday),(atemp),(casual) and (registered) as they are not needed for the analysis or for regression analysis.\n",
    "df.drop(['instant','dteday','casual','registered','atemp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc142e2",
   "metadata": {},
   "source": [
    "# Step 4: Visualising the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Categorical Variables of the Dataset using (boxplot): to see how predictor variables stands against the (cnt).\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2,4,1)\n",
    "sns.boxplot(x = 'weekday', y = 'cnt', data = df)\n",
    "plt.subplot(2,4,2)\n",
    "sns.boxplot(x = 'holiday', y = 'cnt', data = df)\n",
    "plt.subplot(2,4,3)\n",
    "sns.boxplot(x = 'workingday', y = 'cnt', data = df)\n",
    "plt.subplot(2,4,4)\n",
    "sns.boxplot(x = 'month', y = 'cnt', data = df)\n",
    "plt.subplot(2,4,5)\n",
    "sns.boxplot(x = 'year', y = 'cnt', data = df)\n",
    "plt.subplot(2,4,6)\n",
    "sns.boxplot(x = 'season', y = 'cnt', data = df)\n",
    "plt.subplot(2,4,7)\n",
    "sns.boxplot(x = 'weathersit', y = 'cnt', data = df)\n",
    "plt.title('Categorical Variables VS (cnt))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6819038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Numerical Columns.\n",
    "sns.pairplot(data=df,vars=['temp','atemp','humidity','windspeed','cnt'])\n",
    "plt.title('The Numerical Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Heatmap to show the correlation between the variables to see if we can perform linear regression on the dataset or not.\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(df.corr(), cmap='YlRd', annot=True)\n",
    "plt.title('The Correlation Between Variables in the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f681a",
   "metadata": {},
   "source": [
    "We see there are variables correlated to (cnt) such as temp, yr, workingday, so we can thereby conduct a linear regresssion model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e67050",
   "metadata": {},
   "source": [
    "# Step 5: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dummy Variables for (month), (weekday), (weathersit) and (seasons).\n",
    "month = pd.get_dummies(df.mnth, drop_first=True)\n",
    "weekday = pd.get_dummies(df.weekday, drop_first=True)\n",
    "weathersit = pd.get_dummies(df.weathersit, drop_first=True)\n",
    "season = pd.get_dummies(df.season, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Dummy Variables to the Original Dataframe\n",
    "df = pd.concat([df,month, weekday, weathersit, season], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping (month), (weekday), (weathersit) and (seasons) as we have created the dummies for it.\n",
    "df.drop(['season','mnth','weekday','weathersit'], axis = 1, inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a15c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Shape of Dataframe after Data Preparation is done.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Info about Columns after Data Preparation is done.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c94ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Heatmap to show the Correlation between the new variables in the dataset after Data Preparation is done.\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(df.corr(), cmap='YlOrGn', annot=True)\n",
    "plt.title('Correlation between the Variables in the Dataset after Data Preparation is done')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbd665",
   "metadata": {},
   "source": [
    "# Step 6: Preparing the Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2263b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataframe into Train and Test sets.\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(df_new, train_size = 0.7, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Shape of the Train Dataset\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88064ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Shape of the Test Dataset\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling the Variables like (hum), (temp), (windspeed), (cnt) as they have large values Using MinMaxScaler. \n",
    "scaler = MinMaxScaler()\n",
    "scaler_var = ['hum', 'windspeed', 'temp', 'cnt']\n",
    "df_train[scaler_var] = scaler.fit_transform(df_train[scaler_var])\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6839e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the values of the Train set after performing Scaling.\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e31816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Heatmap to show the Correlation coefficients to see which variables are highly correlated after the Data Preparation and Rescaling.\n",
    "plt.figure(figsize = (25,25))\n",
    "matrix = np.triu(df_train.corr())\n",
    "sns.heatmap(df_train.corr(), annot = True, cmap=\"RdYlGn\", mask=matrix)\n",
    "plt.title('Correlation between the Variables in the Dataset after Data Preparation and Rescaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a0c61",
   "metadata": {},
   "source": [
    "We see (cnt) have correlation with (year) and (temp). Similarly, (Misty) and (humidity) show correlation, Spring with Jan and Feb and Summer with May and Winter with Oct and Nov show good correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing one of the correlation (cnt) and (temp) to see the trends via Scatter plot.\n",
    "plt.figure(figsize=[6,6])\n",
    "plt.scatter(df_train.temp, df_train.cnt)\n",
    "plt.title('Correlation between (cnt) vs (temp)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e6bb3",
   "metadata": {},
   "source": [
    "Visualization confirms a positive correlation between cnt and temp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f97e70",
   "metadata": {},
   "source": [
    "# Step 7: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Linear Model.\n",
    "y_train = df_train.pop('cnt')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5404b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the RFE object.\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "rfe = RFE(lm, 15)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the variables that selected in top 15 list.\n",
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the selected variable via RFE in col list.\n",
    "col = X_train.columns[rfe.support_]\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking which columns has been rejected.\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0caf116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to calculate VIF of variables.\n",
    "def calculateVIF(df):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = df.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    return vif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31af13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with RFE selected variables and calculate VIF.\n",
    "X_train_rfe = X_train[col]\n",
    "calculateVIF(X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6558e",
   "metadata": {},
   "source": [
    "We see tha the (humidity) shows high VIF value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As (humidity) shows high VIF values hence we can drop it\n",
    "X_train_new = X_train_rfe.drop(['humidity'], axis = 1)\n",
    "\n",
    "# Run the function to calculate VIF for the new model\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db238b0b",
   "metadata": {},
   "source": [
    "VIF Values seems to be good now, and we will see if we can reduce further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02ebcc",
   "metadata": {},
   "source": [
    "# Step 8: Building a Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the 1st Linear Regression Model.\n",
    "X_train_lm_1 = sm.add_constant(X_train_new)\n",
    "lr_1 = sm.OLS(y_train,X_train_lm_1).fit()\n",
    "print(lr_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop (Nov) variable as it has high (p-value).\n",
    "X_train_new = X_train_new.drop(['Nov'], axis = 1)\n",
    "# Run the function to calculate VIF for the new model.\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166759a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the 2nd Linear Regression Model.\n",
    "X_train_lm_2 = sm.add_constant(X_train_new)\n",
    "lr_2 = sm.OLS(y_train,X_train_lm_2).fit()\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop (Dec) variable as it has high (p-value).\n",
    "X_train_new = X_train_new.drop(['Dec'], axis = 1)\n",
    "# Run the function to calculate VIF for the new model.\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96387e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the 3rd Linear Regression Model.\n",
    "X_train_lm_3 = sm.add_constant(X_train_new)\n",
    "lr_3 = sm.OLS(y_train,X_train_lm_3).fit()\n",
    "print(lr_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop (Jan) variable as it has high (p-value).\n",
    "X_train_new = X_train_new.drop(['Jan'], axis = 1)\n",
    "# Run the function to calculate VIF for the new model.\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the 4th Linear Regression Model.\n",
    "X_train_lm_4 = sm.add_constant(X_train_new)\n",
    "lr_4 = sm.OLS(y_train,X_train_lm_4).fit()\n",
    "print(lr_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c39488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop (July) variable as it has high (p-value).\n",
    "X_train_new = X_train_new.drop(['July'], axis = 1)\n",
    "# Run the function to calculate VIF for the new model.\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6933082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the 5th Linear Regression Model.\n",
    "X_train_lm_5 = sm.add_constant(X_train_new)\n",
    "lr_5 = sm.OLS(y_train,X_train_lm_5).fit()\n",
    "print(lr_5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc471a5",
   "metadata": {},
   "source": [
    "We can cosider the above model i.e lr_5, as it seems to have very low multicolinearity between the predictors and the p-values for all the predictors seems to be significant.\n",
    "F-Statistics value of 248.4 (which is greater than 1) and the p-value of 1.47e-186 i.e almost equals to zero, states that the overall model is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6110d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Parameters and their Coefficient values\n",
    "lr_5.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df23fc",
   "metadata": {},
   "source": [
    "##### Several points to be noted as we select this model as the final model:\n",
    "\n",
    "1) The model selection depends on several factor such as the p-value, the VIF and the R-squared value. The p-value gives us input on the significance of the variables, the VIF about the correaltion between the participating variables and the R-squared value gives us an indication about the strength of the model. This value defines the percentage of the variance in the dependent variable that the independent variables explain collectively.\n",
    "\n",
    "2) The low (<0.05) or almost zero p-value of all the selected variables enables us to reject the null hypothesis. \n",
    "\n",
    "3) The VIF should be generally <5 and we have achieved that condition with all the variables. \n",
    "\n",
    "4) The R-squared value achieved is 82.7% which suggests a high correlation between the dependent variable (count) and the independent variables and the variables selected accurately help us map the variance of the dependent variable ie count. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2620f",
   "metadata": {},
   "source": [
    "# Step 9: Residual Analysis of the Train data and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lm_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89552245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the y_train_pred for Residual Analysis.\n",
    "y_train_pred = lr_5.predict(X_train_lm_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f0bba",
   "metadata": {},
   "source": [
    "#### Normality of Error Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the Error Terms.\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20) \n",
    "plt.xlabel('Errors', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7cfdb",
   "metadata": {},
   "source": [
    "Error Terms are following a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1bea4e",
   "metadata": {},
   "source": [
    "#### Multi Colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Heatmap to show the Correlation X Train.\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(X_train_new.corr(),annot = True, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3446e",
   "metadata": {},
   "source": [
    "VIF values are less than 5, so it's good and there is no multicolinearity are seen from the Heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f03f5b",
   "metadata": {},
   "source": [
    "#### Linearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Relationship Validation Using CCPR plot.\n",
    "sm.graphics.plot_ccpr(lr_5, 'temp')\n",
    "plt.show()\n",
    "sm.graphics.plot_ccpr(lr_5, 'Sep')\n",
    "plt.show()\n",
    "sm.graphics.plot_ccpr(lr_5, 'windspeed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147cecf6",
   "metadata": {},
   "source": [
    "Linearity can be observed from above visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04030d",
   "metadata": {},
   "source": [
    "#### Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33621b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making polt for Residuals.\n",
    "y_train_pred = lr_5.predict(X_train_lm_5)\n",
    "residual = y_train - y_train_pred\n",
    "sns.scatterplot(y_train,residual)\n",
    "plt.plot(y_train,(y_train - y_train), '-r')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e2fcc",
   "metadata": {},
   "source": [
    "No visible pattern observed from above plot for residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525ae179",
   "metadata": {},
   "source": [
    "#### Independence of residuals\n",
    "\n",
    "Durbin-Watson value of final model lr_5 is 2.085, which signifies there is no autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6c6e7",
   "metadata": {},
   "source": [
    "# Step 10: Making Predictions Using the Final Model\n",
    "Now that we have fitted the model and checked the normality of error terms, Now we will go ahead and make predictions using the final, i.e. 5th model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37463e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying scaling on the Test Dataset.\n",
    "num_vars = ['temp', 'humidity', 'windspeed','cnt']\n",
    "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb810423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Description of the Columns of the Test Dataset.\n",
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.pop('cnt')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = X_train_new.columns\n",
    "X_test = X_test[col1]\n",
    "# Adding constant variable to Test Dataframe.\n",
    "X_test_lm_5 = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_5.predict(X_test_lm_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "round(r2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a8c41",
   "metadata": {},
   "source": [
    "# Step 11: Model Evaluation\n",
    "\n",
    "Plot the graph for actual versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331617e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "fig.suptitle('y_test vs y_pred', fontsize = 20) \n",
    "plt.xlabel('y_test', fontsize = 18)\n",
    "plt.ylabel('y_pred', fontsize = 16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807cd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(lr_5.params,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c5829",
   "metadata": {},
   "source": [
    "We can see that the equation of our best fitted line is:\n",
    "\n",
    "$ cnt = 0.1909 + 0.2341  \\times  year - 0.0963  \\times  holiday + 0.4777 \\times temp - 0.1481 \\times windspeed + 0.0910 \\times sep - 0.2850 \\times Light_snowrain - 0.0787 \\times Misty - 0.0554 \\times spring + 0.0621 \\times summer + 0.0945 \\times winter $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0538727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Adjusted-R^2 value for the test dataset\n",
    "adjusted_r2 = round(1-(1-r2)*(X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1),4)\n",
    "print(adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3af213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the fit on the Test Data.\n",
    "# plotting a Regression plot\n",
    "plt.figure()\n",
    "sns.regplot(x=y_test, y=y_pred, ci=68, fit_reg=True,scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\n",
    "plt.title('y_test vs y_pred', fontsize=20)\n",
    "plt.xlabel('y_test', fontsize=18)\n",
    "plt.ylabel('y_pred', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60028dfa",
   "metadata": {},
   "source": [
    "# Comparision between Training and Testing dataset:\n",
    "    - Train dataset R^2          : 0.833\n",
    "    - Test dataset R^2           : 0.8038\n",
    "    - Train dataset Adjusted R^2 : 0.829    \n",
    "    - Test dataset Adjusted R^2  : 0.7944\n",
    "\n",
    "#### Demand of bikes depend on year, holiday, temp, windspeed, sep, Light_snowrain, Misty, spring, summer and winter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d803f4",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "The summary of the model after data interpretation, visualisation, data-preparation, model building and training, residual analysis and evaluation of test model are as follows-\n",
    "\n",
    "1) The R-squared value of the train set is 82.71% whereas the test set has a value of 81.13% which suggests that our model broadly explains the variance quite accurately on the test set and thus we can conclude that it is a good model. \n",
    "\n",
    "2) Our developed model's mean squared error is almost 0 on both the training and testing datasets which suggests that the variance is accurately predicted on the test set. The p-values and VIF were used to select the significant variables. RFE was also conducted for automated selection of variables.  \n",
    "\n",
    "3) We can conclude that the bike demands for the BoomBikes is company is dependent on the temperature and whether it is a workingday or not. Additionally more rentals seem to be demanded on the winters as compared to the summer and spring. We had observed that the months of September and October had higher use of rentals. In terms of days the maximum focus was on days like Wed, Thurs and Sat and more on holidays. \n",
    "\n",
    "4) These interpretations help us derive meaningful insights in the bike rental market and the behaviour of the people. One of the recommendations based on this model are that there should be aggressive marketing in the summer and spring season to drive up rentals. Since the summer months also show low rental levels, a strong marketing strategy for the first 6 months of the year can assist in driving up the rental numbers. There has to be an approach required to introduce more users on days where the weather is less clear, perhaps with incentives or strategic deals. Rentals were more in 2019 than 2018 which suggests that over time more people would be exposed to this idea and there has to a strong analysis done to retain the repeat customers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
